{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "import keras\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'validation_set', 'training_set']\n"
     ]
    }
   ],
   "source": [
    "IMG_PATH = \"data/\"\n",
    "print(os.listdir(IMG_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = IMG_PATH + \"training_set/\"\n",
    "validation_path = IMG_PATH + \"validation_set/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_imgs(path):\n",
    "    print(path)\n",
    "    for value in os.listdir(path):\n",
    "        print(value, \"has\", len(os.listdir(path + value)), \"imgs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/training_set/\n",
      "hemmorhage_data has 80 imgs\n",
      "non_hemmorhage_data has 80 imgs\n",
      "data/validation_set/\n",
      "hemmorhage_data has 21 imgs\n",
      "non_hemmorhage_data has 20 imgs\n"
     ]
    }
   ],
   "source": [
    "number_of_imgs(train_path)\n",
    "number_of_imgs(validation_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 224, 224\n",
    "nb_train_samples = 160\n",
    "nb_validation_samples = 41\n",
    "epochs = 25\n",
    "batch_size = 6\n",
    "checkpoint_filepath = \"checkpoint/model2_val_loss-{val_loss:.2f}.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0826 12:42:27.432030 139696020285184 deprecation_wrapper.py:119] From /home/h8953/tensorflow_gpu_env/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0826 12:42:27.444600 139696020285184 deprecation_wrapper.py:119] From /home/h8953/tensorflow_gpu_env/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0826 12:42:27.446919 139696020285184 deprecation_wrapper.py:119] From /home/h8953/tensorflow_gpu_env/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0826 12:42:27.467457 139696020285184 deprecation_wrapper.py:119] From /home/h8953/tensorflow_gpu_env/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0826 12:42:27.693251 139696020285184 deprecation_wrapper.py:119] From /home/h8953/tensorflow_gpu_env/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0826 12:42:27.693867 139696020285184 deprecation_wrapper.py:119] From /home/h8953/tensorflow_gpu_env/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "conv_base = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for layer in conv_base.layers:\n",
    "    #layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0826 12:42:28.467057 139696020285184 deprecation.py:506] From /home/h8953/tensorflow_gpu_env/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0826 12:42:28.495534 139696020285184 deprecation_wrapper.py:119] From /home/h8953/tensorflow_gpu_env/lib/python3.5/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0826 12:42:28.501941 139696020285184 deprecation.py:323] From /home/h8953/tensorflow_gpu_env/lib/python3.5/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(Flatten())                                    \n",
    "model.add(Dense(64))                                    \n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))                                     \n",
    "model.add(Activation('sigmoid'))            \n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(lr=0.0001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                1605696   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 16,320,449\n",
      "Trainable params: 16,320,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n",
      "Found 41 images belonging to 2 classes.\n",
      "Epoch 1/25\n",
      "26/26 [==============================] - 7s 287ms/step - loss: 0.8006 - acc: 0.5192 - val_loss: 0.6949 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69493, saving model to checkpoint/model2_val_loss-0.69.h5\n",
      "Epoch 2/25\n",
      "26/26 [==============================] - 6s 229ms/step - loss: 0.6903 - acc: 0.6090 - val_loss: 0.7125 - val_acc: 0.4571\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.69493\n",
      "Epoch 3/25\n",
      "26/26 [==============================] - 4s 158ms/step - loss: 0.6982 - acc: 0.5033 - val_loss: 0.7114 - val_acc: 0.5143\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.69493\n",
      "Epoch 4/25\n",
      "26/26 [==============================] - 4s 160ms/step - loss: 0.6987 - acc: 0.5159 - val_loss: 0.6958 - val_acc: 0.4857\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.69493\n",
      "Epoch 5/25\n",
      "26/26 [==============================] - 4s 165ms/step - loss: 0.7023 - acc: 0.4936 - val_loss: 0.7048 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.69493\n",
      "Epoch 6/25\n",
      "26/26 [==============================] - 4s 161ms/step - loss: 0.6957 - acc: 0.4905 - val_loss: 0.6706 - val_acc: 0.6571\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.69493 to 0.67064, saving model to checkpoint/model2_val_loss-0.67.h5\n",
      "Epoch 7/25\n",
      "26/26 [==============================] - 4s 161ms/step - loss: 0.6857 - acc: 0.5705 - val_loss: 0.6676 - val_acc: 0.5143\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.67064 to 0.66759, saving model to checkpoint/model2_val_loss-0.67.h5\n",
      "Epoch 8/25\n",
      "26/26 [==============================] - 4s 162ms/step - loss: 0.6729 - acc: 0.5895 - val_loss: 0.5891 - val_acc: 0.6389\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.66759 to 0.58907, saving model to checkpoint/model2_val_loss-0.59.h5\n",
      "Epoch 9/25\n",
      "26/26 [==============================] - 4s 163ms/step - loss: 0.6200 - acc: 0.7276 - val_loss: 0.4438 - val_acc: 0.7714\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.58907 to 0.44380, saving model to checkpoint/model2_val_loss-0.44.h5\n",
      "Epoch 10/25\n",
      "26/26 [==============================] - 4s 161ms/step - loss: 0.6448 - acc: 0.7147 - val_loss: 0.3601 - val_acc: 0.8857\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.44380 to 0.36014, saving model to checkpoint/model2_val_loss-0.36.h5\n",
      "Epoch 11/25\n",
      "26/26 [==============================] - 4s 164ms/step - loss: 0.3524 - acc: 0.8525 - val_loss: 0.9267 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.36014\n",
      "Epoch 12/25\n",
      "26/26 [==============================] - 4s 165ms/step - loss: 0.3385 - acc: 0.8717 - val_loss: 0.2112 - val_acc: 0.9429\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.36014 to 0.21124, saving model to checkpoint/model2_val_loss-0.21.h5\n",
      "Epoch 13/25\n",
      "26/26 [==============================] - 4s 166ms/step - loss: 0.2173 - acc: 0.8974 - val_loss: 0.2204 - val_acc: 0.8857\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.21124\n",
      "Epoch 14/25\n",
      "26/26 [==============================] - 4s 165ms/step - loss: 0.1334 - acc: 0.9743 - val_loss: 0.4079 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.21124\n",
      "Epoch 15/25\n",
      "26/26 [==============================] - 4s 165ms/step - loss: 0.1580 - acc: 0.9295 - val_loss: 0.2029 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.21124 to 0.20291, saving model to checkpoint/model2_val_loss-0.20.h5\n",
      "Epoch 16/25\n",
      "26/26 [==============================] - 4s 163ms/step - loss: 0.1487 - acc: 0.9295 - val_loss: 0.2611 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.20291\n",
      "Epoch 17/25\n",
      "26/26 [==============================] - 4s 164ms/step - loss: 0.1818 - acc: 0.9615 - val_loss: 0.1509 - val_acc: 0.9714\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.20291 to 0.15092, saving model to checkpoint/model2_val_loss-0.15.h5\n",
      "Epoch 18/25\n",
      "26/26 [==============================] - 4s 164ms/step - loss: 0.1559 - acc: 0.9456 - val_loss: 0.4268 - val_acc: 0.8286\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.15092\n",
      "Epoch 19/25\n",
      "26/26 [==============================] - 4s 164ms/step - loss: 0.2635 - acc: 0.9007 - val_loss: 0.3127 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.15092\n",
      "Epoch 20/25\n",
      "26/26 [==============================] - 4s 164ms/step - loss: 0.1883 - acc: 0.9423 - val_loss: 0.4788 - val_acc: 0.8286\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.15092\n",
      "Epoch 21/25\n",
      "26/26 [==============================] - 4s 165ms/step - loss: 0.2186 - acc: 0.9166 - val_loss: 0.4148 - val_acc: 0.8857\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.15092\n",
      "Epoch 22/25\n",
      "26/26 [==============================] - 4s 164ms/step - loss: 0.1569 - acc: 0.9423 - val_loss: 0.3201 - val_acc: 0.8611\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.15092\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 23/25\n",
      "26/26 [==============================] - 4s 163ms/step - loss: 0.0508 - acc: 0.9808 - val_loss: 0.7270 - val_acc: 0.8286\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.15092\n",
      "Epoch 24/25\n",
      "26/26 [==============================] - 4s 165ms/step - loss: 0.0327 - acc: 1.0000 - val_loss: 0.4540 - val_acc: 0.8286\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.15092\n",
      "Epoch 25/25\n",
      "26/26 [==============================] - 4s 163ms/step - loss: 0.0218 - acc: 1.0000 - val_loss: 0.6660 - val_acc: 0.8857\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.15092\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0cfadcfa90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    rescale=1. / 255,                   #Scaling RGB values from \"0-255\" to \"0-1\" \n",
    "    zoom_range=0.2,                 #Random zoom between 0 and 0.2\n",
    "    horizontal_flip=True) #Random horizontal flip\n",
    "               \n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255) #Scaling RGB values from \"0-255\" to \"0-1\". \n",
    "\n",
    "\n",
    "# Generates batches of image data for training\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,                                       #Train data directory\n",
    "    target_size=(img_width, img_height),                  #Image size\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\")                                  #Amount of classes, binary if 2 classes, else categorical\n",
    "\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_path,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\")\n",
    "\n",
    "\n",
    "# Lowering learning rate if no progress is made.\n",
    "\n",
    "reduce_learning_rate = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.1,\n",
    "    patience=5,\n",
    "    min_lr=0.00001,\n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "# Defining checkpoint that saves the best model or model\"s weights based on the value that we are monitoring.\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    checkpoint_filepath,\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    #save_weights_only=True,\n",
    "    mode=\"min\")\n",
    "\n",
    "\n",
    "# Defining callbacks which includes checkpoint and reducing learning rate on plateau.\n",
    "\n",
    "callbacks = [checkpoint, reduce_learning_rate]\n",
    "\n",
    "# Training CNN\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,         \n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size,\n",
    "    callbacks=callbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_gpu_env",
   "language": "python",
   "name": "tensorflow_gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
